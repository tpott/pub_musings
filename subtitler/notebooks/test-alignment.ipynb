{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from typing import (Any, Dict, List, Tuple)\n",
    "\n",
    "import IPython\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "\n",
    "\n",
    "print('IPython.__version__ = %s' % IPython.__version__)\n",
    "print('numpy.__version__ = %s' % np.__version__)\n",
    "print('matplotlib.__version__ = %s' % matplotlib.__version__)\n",
    "print('scipy.__version__ = %s' % scipy.__version__)\n",
    "print('sklearn.__version__ = %s' % sklearn.__version__)\n",
    "\n",
    "print('\\nseeding random with %d\\n' % int(\"4ec4215f92cf3e\", 16))\n",
    "random.seed(int(\"4ec4215f92cf3e\", 16))\n",
    "\n",
    "with open('/proc/%d/status' % os.getpid(), 'rb') as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelly_wife_or_dog = 'wr2sVPTacTE'\n",
    "dhoom_taana = 'TjUXr560Gu0'\n",
    "video_name = kelly_wife_or_dog\n",
    "# video_name = dhoom_taana\n",
    "rate, data = scipy.io.wavfile.read('../audios/%s.wav' % video_name)\n",
    "print('data.shape = %s' % str(data.shape))\n",
    "print('data.dtype = %s' % data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = data.shape[0] / rate\n",
    "print('number of channels = %d' % data.shape[1])\n",
    "print('length = %f seconds' % length)\n",
    "\n",
    "if data.shape[1] > 1:\n",
    "    print('selecting channel 0')\n",
    "    data = data[:, 0]\n",
    "    \n",
    "limit = 120\n",
    "if length > limit:\n",
    "    print('shortening to %d seconds' % limit)\n",
    "    data = data[:limit * rate].copy()\n",
    "    length = float(limit)\n",
    "    \n",
    "print('final shape = %s' % str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided to use `stft` instead of `spectrogram` because it seemed simpler to understand it's\n",
    "# \"window\" and \"overlap\" arguments.\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.stft.html vs\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html . \n",
    "# The `spectrogram` documentation has a nice overview, but does a poor job at explaining\n",
    "# windows with respect to the `window` argument. I tried also looking at\n",
    "# https://homes.cs.washington.edu/~thickstn/spectrograms.html but ultimately settled on\n",
    "# `stft`. Note that the result of `stft` is in the complex domain, so we have to use the\n",
    "# magnitude to get a real value.\n",
    "window_size = int(rate) // 100\n",
    "step_size = window_size // 2\n",
    "windows_per_second = int(rate) // step_size\n",
    "freqs, times, spectro = scipy.signal.stft(\n",
    "    data,\n",
    "    rate,\n",
    "    window='hann', # default, as specified by the documentation (listed above)\n",
    "    nperseg=window_size,\n",
    "    noverlap=window_size // 2\n",
    ")\n",
    "# Note that my interpretation of spectro is more like spectro.T. In that, each row in\n",
    "# spectro.T represents the frequency strengths at a particular time. Specifically,\n",
    "# spectro.T[0] represents the first 10 ms of `data`\n",
    "print('data.shape = %s' % str(data.shape))\n",
    "print('spectro.shape = %s' % str(spectro.shape))\n",
    "print('(spectro.shape[0] - 1) * (spectro.shape[1] - 1) = %d' % ((spectro.shape[0] - 1) * (spectro.shape[1] - 1)))\n",
    "print('spectro.dtype = %s' % spectro.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = np.linspace(0, length, data.shape[0])\n",
    "plt.plot(time_range, data, label='channel 0')\n",
    "\n",
    "# Some interesting markers\n",
    "if video_name == dhoom_taana:\n",
    "    # The start of the chorus\n",
    "    plt.axvline(x=34, color='#d62728')\n",
    "    # The start of the solo singer, \"Kaise, ...\"\n",
    "    plt.axvline(x=43, color='#d62728')\n",
    "elif video_name == kelly_wife_or_dog:\n",
    "    # The long, slow \"Sooooo, Kelly...\"\n",
    "    plt.axvline(x=11.8, color='#d62728')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.gcf().set_size_inches([15, 4]) # default is 6 x 4\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = np.linspace(0, limit, spectro.shape[1])\n",
    "signal1 = np.abs(spectro).T[:, :5].sum(axis=1)\n",
    "signal2 = np.abs(spectro).T[:, 5:10].sum(axis=1)\n",
    "plt.plot(time_range, signal1, label='sum(freqs[:5])')\n",
    "plt.plot(time_range, signal2, label='sum(freqs[5:10])')\n",
    "\n",
    "# Some interesting markers\n",
    "if video_name == dhoom_taana:\n",
    "    # The start of the chorus\n",
    "    plt.axvline(x=34, color='#d62728')\n",
    "    # The start of the solo singer, \"Kaise, ...\"\n",
    "    plt.axvline(x=43, color='#d62728')\n",
    "elif video_name == kelly_wife_or_dog:\n",
    "    # The long, slow \"Sooooo, Kelly...\"\n",
    "    plt.axvline(x=11.8, color='#d62728')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.gcf().set_size_inches([15, 4]) # default is 6 x 4\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using `np.arange(freqs.shape[0])` instead of `freqs` directly\n",
    "# because that's just how I think about frequencies...\n",
    "plt.pcolormesh(times, np.arange(freqs.shape[0])[:60], np.abs(spectro)[:60, :])\n",
    "\n",
    "# Some interesting markers\n",
    "if video_name == dhoom_taana:\n",
    "    # The start of the chorus\n",
    "    plt.axvline(x=34, color='#d62728')\n",
    "    # The start of the solo singer, \"Kaise, ...\"\n",
    "    plt.axvline(x=43, color='#d62728')\n",
    "elif video_name == kelly_wife_or_dog:\n",
    "    # The long, slow \"Sooooo, Kelly...\"\n",
    "    plt.axvline(x=11.8, color='#d62728')\n",
    "    \n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.gcf().set_size_inches([15, 4]) # default is 6 x 4\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the transpose of `data` (`data.T`) because IPython expects\n",
    "# a different shape than what scipy returns.\n",
    "# https://stackoverflow.com/questions/57137050/i-am-facing-problems-displaying-audio-file-using-python\n",
    "IPython.display.Audio(data=data.T, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts at about ~34 seconds\n",
    "dhoom_taana_lyrics = \"\"\"\n",
    "Dhoom Taana Ta Dum Ta Na Na Na\n",
    "Dhoom Taana Ta Dum Ta Na Na Na\n",
    "Dhoom Taana Dhir Na Dhir Na...\n",
    "\n",
    "Kaise, Naino Se Nain Milao Sajna\n",
    "Kaise, Mein Aise Na Ghabrao Sajna\n",
    "Kaise, Aaye Na Aise Mohe Laaj Sajna\n",
    "Choona Na Dehko Mohe Aaj Sajna\n",
    "\"\"\"\n",
    "# Ends half way through \"mohe\" (doesn't get to finish \"aaj sajna\").\n",
    "# Per line, there are 8, 8, and 6 sounds and then 6, 6, 7, and finally\n",
    "# 3.5 words that are uttered in the first 60 seconds of the song.\n",
    "\n",
    "dhoom_taana_utterances = [\n",
    "    {'start': 34, 'end': 34.2, 'duration': 0.2, 'content': 'dhoom'},\n",
    "    {'start': 43, 'end': 43.9, 'duration': 0.9, 'content': 'kaise'},\n",
    "    {'start': 47.5, 'end': 48.1, 'duration': 0.6, 'content': 'kaise'},\n",
    "    {'start': 51.5, 'end': 52.1, 'duration': 0.6, 'content': 'kaise'},\n",
    "]\n",
    "\n",
    "kelly_wife_or_dog_utterances = []\n",
    "with open('../outputs/%s.json' % kelly_wife_or_dog, 'rb') as f:\n",
    "    raw_output = json.loads(f.read().decode('utf-8'))\n",
    "    \n",
    "result_items = raw_output['results']['items']\n",
    "for item in result_items:\n",
    "    if 'start_time' not in item:\n",
    "        continue\n",
    "    start_time = float(item['start_time'])\n",
    "    if start_time > limit:\n",
    "        continue\n",
    "    end_time = float(item['end_time'])\n",
    "    kelly_wife_or_dog_utterances.append({\n",
    "        'start': start_time,\n",
    "        'end': end_time,\n",
    "        'duration': end_time - start_time,\n",
    "        'content': item['alternatives'][0]['content'],\n",
    "    })\n",
    "    print(kelly_wife_or_dog_utterances[-1])\n",
    "\n",
    "utterances = []\n",
    "if video_name == dhoom_taana:\n",
    "    utterances = dhoom_taana_utterances\n",
    "elif video_name == kelly_wife_or_dog:\n",
    "    utterances = kelly_wife_or_dog_utterances\n",
    "    \n",
    "print('num utterances = %d' % len(utterances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelsFromUtterances(utterances: List[Dict[str, Any]], n_rows: int) -> Tuple[int, np.ndarray]:\n",
    "    \"\"\"return: np.ndarray[ndtype=intish, shape=[n_rows]]\"\"\"\n",
    "    positive_examples = 0\n",
    "    labels = np.zeros(n_rows)\n",
    "    for item in utterances:\n",
    "        # math.ceil rounds up to the latest millisecond for labeling\n",
    "        start_i = int(math.ceil(item['start'] * windows_per_second))\n",
    "        end_i = int(math.ceil(item['end'] * windows_per_second))\n",
    "        for i in range(start_i, min(end_i, n_rows)):\n",
    "            labels[i] = 1\n",
    "            positive_examples += 1\n",
    "    return positive_examples, labels\n",
    "\n",
    "\n",
    "def trainFromSpectro(spectro: np.ndarray, utterances: List[Dict[str, Any]]) -> sklearn.tree.DecisionTreeClassifier:\n",
    "    \"\"\"spectro: np.ndarray[ndtype=float64, shape=[Nwindows, Nfreqs]]\"\"\"\n",
    "    # TODO replace Dict with a dataclass\n",
    "    print('spectro.shape = %s' % str(spectro.shape))\n",
    "    \n",
    "    positive_examples, labels = labelsFromUtterances(utterances, spectro.shape[0])\n",
    "    print('got %d positive examples for training' % positive_examples)\n",
    "    print('out of %d leaves %d negative examples (i.e. not talking)' % (spectro.shape[0], spectro.shape[0] - positive_examples))\n",
    "    \n",
    "    classifier = sklearn.tree.DecisionTreeClassifier(\n",
    "        random_state=random.randint(0, 2 ** 32 - 1),\n",
    "        max_depth=5\n",
    "    )\n",
    "    model = classifier.fit(spectro, labels)\n",
    "    plt.gcf().set_size_inches([24, 8]) # default is 6 x 4\n",
    "    sklearn.tree.plot_tree(model, max_depth=2, node_ids=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = trainFromSpectro(np.abs(spectro).T[:, :60], utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def utterancesFromPredictions(min_word_width, predictions):\n",
    "    ones = np.ones(min_word_width)\n",
    "    i = 0\n",
    "    predicted_utterances = []\n",
    "    while i < predictions.shape[0] - min_word_width + 1:\n",
    "        # 0 means ~\"no words are spoken\"\n",
    "        if predictions[i] == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        if (predictions[i : i + min_word_width] != ones).all():\n",
    "            predictions[i] = 0\n",
    "            i += 1\n",
    "            continue\n",
    "        for j in range(i + min_word_width, predictions.shape[0]):\n",
    "            if predictions[j] == 0:\n",
    "                j -= 1\n",
    "                break\n",
    "        predicted_utterances.append({\n",
    "            'start': i / windows_per_second,\n",
    "            'end': j / windows_per_second,\n",
    "            'duration': (j - i) / windows_per_second,\n",
    "            # content is TBD!\n",
    "        })\n",
    "        i = j + 1\n",
    "    return predicted_utterances\n",
    "\n",
    "predictions = model.predict(np.abs(spectro).T[:, :60])\n",
    "# Any prediction shorter than this will be considered noise\n",
    "min_word_width = 8\n",
    "#predictions[:min_word_width] = np.zeros(min_word_width)\n",
    "predicted_utterances = utterancesFromPredictions(min_word_width, predictions)\n",
    "    \n",
    "print('model found %d possible utterances' % len(predicted_utterances))\n",
    "\n",
    "# I'm using `np.arange(freqs.shape[0])` instead of `freqs` directly\n",
    "# because that's just how I think about frequencies...\n",
    "plt.pcolormesh(times, np.arange(freqs.shape[0])[:60], np.abs(spectro)[:60, :])\n",
    "\n",
    "for item in predicted_utterances:\n",
    "    plt.axvline(x=item['start'], color='#d62728')\n",
    "    \n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.gcf().set_size_inches([15, 4]) # default is 6 x 4\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using `np.arange(freqs.shape[0])` instead of `freqs` directly\n",
    "# because that's just how I think about frequencies...\n",
    "plt.pcolormesh(times, np.arange(freqs.shape[0])[:60], np.abs(spectro)[:60, :])\n",
    "\n",
    "for item in utterances:\n",
    "    plt.axvline(x=item['start'], color='#d62728')\n",
    "    \n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.gcf().set_size_inches([15, 4]) # default is 6 x 4\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndSpectro(video) -> Tuple[int, np.ndarray]:\n",
    "    \"\"\"return: np.ndarray[dtype=float64, shape=[Nrows, Nfreqs]]\"\"\"\n",
    "    rate, data = scipy.io.wavfile.read('../audios/%s.wav' % video)\n",
    "    \n",
    "    length = data.shape[0] / rate\n",
    "    if data.shape[1] > 1:\n",
    "        data = data[:, 0]\n",
    "    limit = 10\n",
    "    if length > limit:\n",
    "        data = data[:limit * rate].copy()\n",
    "        length = float(limit)\n",
    "    \n",
    "    window_size = int(rate) // 100\n",
    "    step_size = window_size // 2\n",
    "    windows_per_second = int(rate) // step_size\n",
    "    freqs, times, spectro = scipy.signal.stft(\n",
    "        data,\n",
    "        rate,\n",
    "        window='hann', # default, as specified by the documentation (listed above)\n",
    "        nperseg=window_size,\n",
    "        noverlap=window_size // 2\n",
    "    )\n",
    "    return windows_per_second, freqs, times, np.abs(spectro).T\n",
    "\n",
    "_, freqs, times, dhoom_taana_spectro = readAndSpectro(dhoom_taana)\n",
    "\n",
    "new_predictions = model.predict(dhoom_taana_spectro[:, :60])\n",
    "new_predicted_utterances = utterancesFromPredictions(min_word_width, new_predictions)\n",
    "\n",
    "print('model found %d possible utterances' % len(new_predicted_utterances))\n",
    "\n",
    "# I'm using `np.arange(freqs.shape[0])` instead of `freqs` directly\n",
    "# because that's just how I think about frequencies...\n",
    "plt.pcolormesh(times, np.arange(freqs.shape[0])[:60], dhoom_taana_spectro.T[:60, :])\n",
    "\n",
    "for item in new_predicted_utterances:\n",
    "    plt.axvline(x=item['start'], color='#d62728')\n",
    "    \n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.gcf().set_size_inches([15, 4]) # default is 6 x 4\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/proc/%d/status' % os.getpid(), 'rb') as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
