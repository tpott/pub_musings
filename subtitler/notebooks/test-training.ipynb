{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from typing import (Any, Dict, List, Tuple)\n",
    "\n",
    "# Third party libraries\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "\n",
    "print('IPython.__version__ = %s' % IPython.__version__)\n",
    "print('matplotlib.__version__ = %s' % matplotlib.__version__)\n",
    "print('numpy.__version__ = %s' % np.__version__)\n",
    "print('pandas.__version__ = %s' % pd.__version__)\n",
    "print('scipy.__version__ = %s' % scipy.__version__)\n",
    "print('sklearn.__version__ = %s' % sklearn.__version__)\n",
    "\n",
    "print('\\nseeding random with %d\\n' % int(\"9fe3ddf4da76a6\", 16))\n",
    "random.seed(int(\"9fe3ddf4da76a6\", 16))\n",
    "\n",
    "with open('/proc/%d/status' % os.getpid(), 'rb') as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw audio: ../audios/*.wav\n",
    "# Labels: ../outputs/*.json --> ../labels/*.tsv\n",
    "data_files = []\n",
    "training_files = set([])\n",
    "eval_files = set([])\n",
    "\n",
    "# sampling? first-N-seconds? last-N-seconds? specific time-window?\n",
    "# lazy loading? mono-channel?\n",
    "\n",
    "# Viewing options:\n",
    "# 1) Signal amplitude\n",
    "# 2) Test signal amplitude (examples: sum(freqs[:5]), sum(freqs[5:10]), ...)\n",
    "# 3) Spectrogram pcolormesh\n",
    "# 4) IPython.display.Audio\n",
    "# 5) JSON utterance labels\n",
    "# 6) Time series labels, i.e. for (1-3), `plt.axvline(x=item['start'], color='#d62728')`, TODO: linewidth=wut?\n",
    "# `%matplotlib notebook` may be handy?\n",
    "\n",
    "# want: frames (aka windows) of 10 ms, steps of 5 ms.\n",
    "# datastruct: (file_name, frame index, signal_rate (example: 44.1kHz), raw_signal_vec, freqs_vec (further want: speech_vec + background_vec), label, phoneme)\n",
    "df = pd.DataFrame(data={\n",
    "    'file_name': ['a', 'a', 'a', 'b', 'b'],\n",
    "    'frame_index': [0, 1, 2, 0, 1],\n",
    "    'signal_rate': [44100, 44100, 44100, 44100, 44100],\n",
    "    'window_size': [441, 441, 441, 441, 441],\n",
    "    'step_size': [220, 220, 220, 220, 220],\n",
    "    'window_max_i': [0, 0, 1, 0, 1],\n",
    "    # These are a bit misleading because their length is 2, but window_size says\n",
    "    # they should be 441.\n",
    "    'raw_signal_vec': [[0, 0], [1, 1], [1, 2], [0, 0], [0, 1]],\n",
    "    'freqs_vec': [[0, 0], [1, 0], [2, 1], [0, 0], [0, 1]],\n",
    "    # TODO: fft(fft(raw_signal)) b/c harmonics. consider librosa's \"pitch class\"\n",
    "    'label': [0, 0, 1, None, None],\n",
    "    'phoneme': [None, None, 'a', None, None],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
